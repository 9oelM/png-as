{"version":3,"sources":["~lib/rt/common.ts","~lib/shared/typeinfo.ts","~lib/rt/pure.ts","~lib/rt/tlsf.ts","~lib/gc.ts","src/header.ts","src/chunkTypes.ts","external/types.ts","~lib/staticarray.ts"],"names":[],"mappings":"oNGoRG,AAAkB,AADF,OACc,oBAE9B,AAAkB,AADP,EAAY,KACG,KAAiB,EAAO,4BAIlD,AAAI,EAAO,MAET,AAAK,AAAM,EAAQ,MAInB,AAAK,AAAO,EAAS,AADhB,EAAM,AAAW,MACI,IAAa,KACvC,EAAM,MAER,AAAkC,EAAK,KAArB,EAAK,qBAIvB,AAAW,OACX,AAAI,AAFO,SAED,EAAY,MACtB,AAAI,IAAM,EAAY,MAGtB,AAAI,EAAS,AApIX,EAA2B,AAAC,AAAkB,EAAjB,EAAM,IAAyB,UAqI5D,AA5HA,EAA2B,AAAC,AAAkB,EAAjB,EAAM,IAAyB,IAC5D,KA8HA,AAAI,AAAC,KAEa,AA7JlB,AASA,EAA2B,EAAM,SAoJN,AAAE,EAAK,SAAhC,AApJF,EACA,KAsJE,AAAI,AAAC,KAAO,OAAc,AAAE,EAAK,mBAzGrC,AAAkB,mBAElB,AAAkB,AADF,OACc,oBAM9B,AAAI,AAHY,AADJ,AAAS,qBAIL,KAEd,AAAI,AADU,AAAC,EAAY,GAAc,GAAkB,EAAY,MACzD,SACZ,AAAY,EAAM,IAClB,EAAe,AAAY,AAA0B,EAAzB,EAAY,SAE5B,AADJ,AArHa,AAqHJ,EArH+B,GAAkB,KAAe,aA4HrF,AAAI,EAAY,KAGd,AAAkB,AADH,AADJ,AAnIM,EAA2B,aAqIf,oBAE7B,AAAI,AADU,AAAC,EAAW,GAAc,GAAkB,EAAY,MACxD,WACZ,AAAY,EAAM,IAClB,EAAc,AAAY,AAAyB,EAAxB,EAAW,SAC9B,OAKZ,EAAe,EAAY,MAK3B,AAAkB,AADP,EAAY,KACG,KAAiB,EAAO,4BAClD,AAAkB,AAA4C,EAA5C,EAA2B,IAAyB,mBAGtE,AAAa,EAA2B,GAAiB,KAIzD,AAAI,EAAO,MAET,AAAK,AAAM,EAAQ,MAInB,AAAK,AAAO,EAAS,AADhB,EAAM,AAAW,MACI,IAAa,KACvC,EAAM,MAER,AAAkC,EAAK,KAArB,EAAK,qBAGvB,AAAW,AA9FT,EAA2B,AAAC,AAAkB,EAAjB,EAAM,IAAyB,SA+F9D,EAAa,KACb,EAAa,KACb,AAAI,IAAM,EAAY,MACtB,AAzFE,EAA2B,AAAC,AAAkB,EAAjB,EAAM,IAAyB,IAC5D,KA2FF,OAAe,EAAK,OACpB,AAhHE,EAA2B,EAAM,MACjC,AA+Gc,AAzHd,KAyHiC,EAAK,aAkHxC,AAII,AAAE,EAAM,MADR,AAAE,EAAQ,MADV,EAAS,sBAQb,AAAI,AAFO,AA7MT,UAgNA,AAAkB,EAAS,EAA0B,oBAGrD,AAAI,AAA0B,EAA1B,EAAQ,MAEV,AAAW,OADX,EAAS,OAON,AACE,EAAS,EAA0B,sBAK5C,AAAI,AADO,EAAM,YAQjB,EAAc,AAAmB,EAAW,GAA9B,AAFC,EAAQ,GAEE,OACzB,EAAY,KACZ,EAAY,KAIZ,AADO,AAAkB,EAAQ,GAAO,KAC1B,KACd,AAtOE,EACA,MAuOF,AAAY,EAAM,UAuClB,AAAI,AAAC,AADM,OAKT,AAAI,AADc,EACA,AAFA,OAEe,AAAY,EAAc,KAAe,SAAG,EAE7E,AADO,KACM,KACb,AAAQ,GAAM,OACU,EAAK,KAC3B,AAAY,KAAN,IAAU,KACX,AAAc,MAAG,EAAK,KACzB,AAAkB,EAAJ,SAAN,IAAc,KADY,AAAE,WAFF,AAAE,WAY5B,GAAM,GAAU,EAAiB,KAE7C,AAAO,cAtKT,AAAI,EAAO,MAET,AAAK,AAAM,EAAQ,MAKD,EAAO,SACrB,EAAQ,EAAM,EAAW,AAAW,MAAU,MAGlD,AAAK,AAAO,EAAgB,AADvB,EAAM,AAHO,MAIe,IAAa,KAC9C,EAAM,MAER,AAAkC,EAAK,KAArB,EAAK,qBAKvB,AAAK,AAFO,AAAM,EAAM,SAAO,EAAM,QAc5B,AA1LP,EAA2B,AAAC,AAAkB,AA0LZ,GA1LL,EAAM,IAAyB,QAiL5D,AAAK,AADO,KAAc,EAAO,EAAK,SAMpC,AAAkB,AADV,AAxMV,EAA2B,AAuMpB,AAAW,KAvMe,0BA0MxB,AAAQ,EAAU,AAAS,GAAb,wBAYzB,AAAgB,OAChB,AAAoB,EAAO,mBAI3B,AAAI,AADY,AAAC,EAAY,GAAc,UAEzC,EAAe,EAAQ,EAAY,OAGnC,AADY,AAA8D,EAA5C,EAA2B,MAC1C,AAAC,EAAY,GAAkB,MAC9C,AAAY,EAAM,KAIlB,EAAe,EAAY,MAC3B,AAtRuB,AAsRd,EAtRyC,KAAkB,KAAe,IAsRnF,cAA0B,aA0H5B,AAAmB,kBAxCnB,AAAI,EAAQ,SAA+B,eA2CvC,AAAC,AADO,AAAY,EAAM,AAzCZ,AAAC,EAAO,GAAW,sBA4CjC,AAAyB,IAEzB,AAAyB,IAEzB,AAAI,AAAC,AADG,AAAY,EAAM,SA3D9B,AAAkB,AAAO,AAAC,AADlB,EAAkB,AAAM,AAAC,AADf,IACqC,GAAM,GAAkB,AArQ7E,QA8PF,AAEE,EAAQ,AAAC,EAAM,EAAW,AAAW,KAAU,MAF7C,EAAO,SAQsB,KAAU,KAAa,KAEpD,AAAY,AADM,EAAa,UACJ,KAC7B,AAAI,AAAY,IAAe,KAAG,GAG1B,EAAM,EAAsB,GAAI,EAAqB,KAyDzD,AAAkB,AADV,AAA8B,EAAM,yBASlD,AAAkB,AAAC,QAA8B,mBACjD,EAAe,KACf,EAAa,KACb,EAAe,KACf,AAAY,EAAM,IAClB,AAAa,EAAM,EAAc,SAkEjC,AAAO,AACS,EAAmB,EAAM,IACrC,QDnUJ,AAAI,EAAM,MAlKV,AAAO,AAAC,AADG,AAmKsB,AAAkB,EAAM,iBAlKtB,AAAC,EAAO,2BAC3C,EAAW,EAAO,MAElB,AAAoB,KAAW,yBAsK/B,AAAI,EAAM,MAAa,AAAU,AAAkB,EAAM,gBA9JzD,AAAS,AADE,OACK,SAEhB,AAAoB,KAAW,mBAC/B,AAAI,EAAM,KACR,MAAgB,EAAuB,6BAzDrC,EAAM,MAGR,AAAU,AAAkB,EAAM,YAwDhC,AAAoB,EAAO,uBC+b/B,EAAe,AADC,KACW,MAC3B,AAAY,EAAM,KDtbhB,AAAkB,EAAK,mBACvB,AACE,EAAW,AAA2B,EAAK,GAA/B,EAAO","sourceRoot":"./main.wasm","sourcesContent":["// Alignment guarantees\n\n// @ts-ignore: decorator\n@inline export const AL_BITS: u32 = 4; // 16 bytes to fit up to v128\n// @ts-ignore: decorator\n@inline export const AL_SIZE: usize = 1 << <usize>AL_BITS;\n// @ts-ignore: decorator\n@inline export const AL_MASK: usize = AL_SIZE - 1;\n\n// Extra debugging\n\n// @ts-ignore: decorator\n@inline export const DEBUG = true;\n\n// ╒════════════════ Common block layout (32-bit) ═════════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┤\n// │                           MM info                             │ -16\n// ├───────────────────────────────────────────────────────────────┤\n// │                           GC info                             │ -12\n// ├───────────────────────────────────────────────────────────────┤\n// │                          runtime id                           │ -8\n// ├───────────────────────────────────────────────────────────────┤\n// │                         runtime size                          │ -4\n// ╞═══════════════════════════════════════════════════════════════╡\n// │                              ...                              │ ref\n@unmanaged export class BLOCK {\n  /** Memory manager info. */\n  mmInfo: usize; // WASM64 needs adaption\n  /** Garbage collector info. */\n  gcInfo: u32;\n  /** Runtime class id. */\n  rtId: u32;\n  /** Runtime object size. */\n  rtSize: u32;\n}\n\n// @ts-ignore: decorator\n@inline export const BLOCK_OVERHEAD: usize = (offsetof<BLOCK>() + AL_MASK) & ~AL_MASK;\n\n// @ts-ignore: decorator\n@inline export const BLOCK_MAXSIZE: usize = (1 << 30) - BLOCK_OVERHEAD;\n","// This file is shared with the compiler and must remain portable\n\n// ╒═══════════════════ Typeinfo interpretation ═══════════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┤ ◄─ __rtti_base\n// │                             count                             │\n// ╞═══════════════════════════════════════════════════════════════╡ ┐\n// │                      Typeinfo#flags [id=0]                    │ id < count\n// ├ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┤\n// │                      Typeinfo#base  [id=0]                    │\n// ├───────────────────────────────────────────────────────────────┤\n// │                              ...                              │\n\n/** Runtime type information data structure. */\n@unmanaged\nexport class Typeinfo {\n  /** Flags describing the shape of this class type. */\n  flags: TypeinfoFlags;\n  /** Base class id or `0` if none. */\n  base: u32;\n}\n\n/** Runtime type information flags. */\nexport const enum TypeinfoFlags {\n  /** No specific flags. */\n  NONE = 0,\n  /** Type is an `ArrayBufferView`. */\n  ARRAYBUFFERVIEW = 1 << 0,\n  /** Type is an `Array`. */\n  ARRAY = 1 << 1,\n  /** Type is a `Set`. */\n  SET = 1 << 2,\n  /** Type is a `Map`. */\n  MAP = 1 << 3,\n  /** Type is inherently acyclic. */\n  ACYCLIC = 1 << 4,\n  /** Value alignment of 1 byte. */\n  VALUE_ALIGN_0 = 1 << 5,\n  /** Value alignment of 2 bytes. */\n  VALUE_ALIGN_1 = 1 << 6,\n  /** Value alignment of 4 bytes. */\n  VALUE_ALIGN_2 = 1 << 7,\n  /** Value alignment of 8 bytes. */\n  VALUE_ALIGN_3 = 1 << 8,\n  /** Value alignment of 16 bytes. */\n  VALUE_ALIGN_4 = 1 << 9,\n  /** Value is a signed type. */\n  VALUE_SIGNED = 1 << 10,\n  /** Value is a float type. */\n  VALUE_FLOAT = 1 << 11,\n  /** Value type is nullable. */\n  VALUE_NULLABLE = 1 << 12,\n  /** Value type is managed. */\n  VALUE_MANAGED = 1 << 13,\n  /** Key alignment of 1 byte. */\n  KEY_ALIGN_0 = 1 << 14,\n  /** Key alignment of 2 bytes. */\n  KEY_ALIGN_1 = 1 << 15,\n  /** Key alignment of 4 bytes. */\n  KEY_ALIGN_2 = 1 << 16,\n  /** Key alignment of 8 bytes. */\n  KEY_ALIGN_3 = 1 << 17,\n  /** Key alignment of 16 bytes. */\n  KEY_ALIGN_4 = 1 << 18,\n  /** Key is a signed type. */\n  KEY_SIGNED = 1 << 19,\n  /** Key is a float type. */\n  KEY_FLOAT = 1 << 20,\n  /** Key type is nullable. */\n  KEY_NULLABLE = 1 << 21,\n  /** Key type is managed. */\n  KEY_MANAGED = 1 << 22\n}\n","import { DEBUG, BLOCK_OVERHEAD } from \"rt/common\";\nimport { Block, freeBlock, ROOT } from \"rt/tlsf\";\nimport { TypeinfoFlags } from \"shared/typeinfo\";\nimport { onincrement, ondecrement, onfree, onalloc } from \"./rtrace\";\n\n/////////////////////////// A Pure Reference Counting Garbage Collector ///////////////////////////\n// see:     https://researcher.watson.ibm.com/researcher/files/us-bacon/Bacon03Pure.pdf\n\n// ╒══════════════════════ GC Info structure ══════════════════════╕\n// │  3                   2                   1                    │\n// │1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0│\n// ├─┼─┴─┴─┼─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┤\n// │B│color│                     refCount                          │\n// └─┴─────┴───────────────────────────────────────────────────────┘\n// B: buffered\n\n// @ts-ignore: decorator\n@inline const BUFFERED_MASK: u32 = 1 << ((sizeof<u32>() * 8) - 1);\n// @ts-ignore: decorator\n@inline const COLOR_BITS = 3;\n// @ts-ignore: decorator\n@inline const COLOR_SHIFT: u32 = ctz(BUFFERED_MASK) - COLOR_BITS;\n// @ts-ignore: decorator\n@inline const COLOR_MASK: u32 = ((1 << COLOR_BITS) - 1) << COLOR_SHIFT;\n// @ts-ignore: decorator\n@inline export const REFCOUNT_MASK: u32 = (1 << COLOR_SHIFT) - 1;\n\n// ╒════════╤═══════════════════ Colors ═══════════════════════════╕\n// │ Color  │ Meaning                                              │\n// ├────────┼──────────────────────────────────────────────────────┤\n// │ BLACK  │ In use or free                                       │\n// │ GRAY   │ Possible member of cycle                             │\n// │ WHITE  │ Member of garbage cycle                              │\n// │ PURPLE │ Possible root of cycle                               │\n// │ RED    │ Candidate cycle undergoing Σ-computation *concurrent │\n// │ ORANGE │ Candidate cycle awaiting epoch boundary  *concurrent │\n// └────────┴──────────────────────────────────────────────────────┘\n// Acyclic detection has been decoupled, hence no GREEN.\n\n// @ts-ignore: decorator\n@inline const COLOR_BLACK: u32 = 0 << COLOR_SHIFT;\n// @ts-ignore: decorator\n@inline const COLOR_GRAY: u32 = 1 << COLOR_SHIFT;\n// @ts-ignore: decorator\n@inline const COLOR_WHITE: u32 = 2 << COLOR_SHIFT;\n// @ts-ignore: decorator\n@inline const COLOR_PURPLE: u32 = 3 << COLOR_SHIFT;\n// @ts-ignore: decorator\n// @inline const COLOR_RED: u32 = 4 << COLOR_SHIFT;\n// @ts-ignore: decorator\n// @inline const COLOR_ORANGE: u32 = 5 << COLOR_SHIFT;\n\n// @ts-ignore: decorator\n@inline const VISIT_DECREMENT = 1; // guard 0\n// @ts-ignore: decorator\n@inline const VISIT_MARKGRAY = 2;\n// @ts-ignore: decorator\n@inline const VISIT_SCAN = 3;\n// @ts-ignore: decorator\n@inline const VISIT_SCANBLACK = 4;\n// @ts-ignore: decorator\n@inline const VISIT_COLLECTWHITE = 5;\n\n// @ts-ignore: decorator\n@global @unsafe @lazy\nfunction __visit(ref: usize, cookie: i32): void {\n  if (ref < __heap_base) return;\n  if (isDefined(__GC_ALL_ACYCLIC)) {\n    if (DEBUG) assert(cookie == VISIT_DECREMENT);\n    decrement(changetype<Block>(ref - BLOCK_OVERHEAD));\n  } else {\n    let s = changetype<Block>(ref - BLOCK_OVERHEAD);\n    switch (cookie) {\n      case VISIT_DECREMENT: {\n        decrement(s);\n        break;\n      }\n      case VISIT_MARKGRAY: {\n        if (DEBUG) assert((s.gcInfo & REFCOUNT_MASK) > 0);\n        s.gcInfo = s.gcInfo - 1;\n        markGray(s);\n        break;\n      }\n      case VISIT_SCAN: {\n        scan(s);\n        break;\n      }\n      case VISIT_SCANBLACK: {\n        let info = s.gcInfo;\n        assert((info & ~REFCOUNT_MASK) == ((info + 1) & ~REFCOUNT_MASK)); // overflow\n        s.gcInfo = info + 1;\n        if ((info & COLOR_MASK) != COLOR_BLACK) {\n          scanBlack(s);\n        }\n        break;\n      }\n      case VISIT_COLLECTWHITE: {\n        collectWhite(s);\n        break;\n      }\n      default: if (DEBUG) assert(false);\n    }\n  }\n}\n\n/** Increments the reference count of the specified block by one.*/\nfunction increment(s: Block): void {\n  var info = s.gcInfo;\n  assert((info & ~REFCOUNT_MASK) == ((info + 1) & ~REFCOUNT_MASK)); // overflow\n  s.gcInfo = info + 1;\n  if (isDefined(ASC_RTRACE)) onincrement(s);\n  if (DEBUG) assert(!(s.mmInfo & 1)); // used\n}\n\n/** Decrements the reference count of the specified block by one, possibly freeing it. */\n// @ts-ignore: decorator\n@lazy\nfunction decrement(s: Block): void {\n  var info = s.gcInfo;\n  var rc = info & REFCOUNT_MASK;\n  if (isDefined(ASC_RTRACE)) ondecrement(s);\n  if (DEBUG) assert(!(s.mmInfo & 1)); // used\n  if (rc == 1) {\n    __visit_members(changetype<usize>(s) + BLOCK_OVERHEAD, VISIT_DECREMENT);\n    if (isDefined(__GC_ALL_ACYCLIC)) {\n      if (DEBUG) assert(!(info & BUFFERED_MASK));\n      freeBlock(ROOT, s);\n    } else {\n      if (!(info & BUFFERED_MASK)) {\n        freeBlock(ROOT, s);\n      } else {\n        s.gcInfo = BUFFERED_MASK | COLOR_BLACK | 0;\n      }\n    }\n  } else {\n    if (DEBUG) assert(rc > 0);\n    if (isDefined(__GC_ALL_ACYCLIC)) {\n      s.gcInfo = (info & ~REFCOUNT_MASK) | (rc - 1);\n    } else {\n      if (!(__typeinfo(s.rtId) & TypeinfoFlags.ACYCLIC)) {\n        s.gcInfo = BUFFERED_MASK | COLOR_PURPLE | (rc - 1);\n        if (!(info & BUFFERED_MASK)) {\n          appendRoot(s);\n        }\n      } else {\n        s.gcInfo = (info & ~REFCOUNT_MASK) | (rc - 1);\n      }\n    }\n  }\n}\n\n/** Buffer of possible roots. */\n// @ts-ignore: decorator\n@lazy var ROOTS: usize;\n/** Current absolute offset into the `ROOTS` buffer. */\n// @ts-ignore: decorator\n@lazy var CUR: usize = 0;\n/** Current absolute end offset into the `ROOTS` buffer. */\n// @ts-ignore: decorator\n@lazy var END: usize = 0;\n\n/** Appends a block to possible roots. */\nfunction appendRoot(s: Block): void {\n  var cur = CUR;\n  if (cur >= END) {\n    growRoots(); // TBD: either that or pick a default and force collection on overflow\n    cur = CUR;\n  }\n  store<Block>(cur, s);\n  CUR = cur + sizeof<usize>();\n}\n\n/** Grows the roots buffer if it ran full. */\nfunction growRoots(): void {\n  var oldRoots = ROOTS;\n  var oldSize = CUR - oldRoots;\n  var newSize = max(oldSize * 2, 64 << alignof<usize>());\n  var newRoots = __alloc(newSize, 0);\n  if (isDefined(ASC_RTRACE)) onfree(changetype<Block>(newRoots - BLOCK_OVERHEAD)); // neglect unmanaged\n  memory.copy(newRoots, oldRoots, oldSize);\n  if (oldRoots) {\n    if (isDefined(ASC_RTRACE)) onalloc(changetype<Block>(oldRoots - BLOCK_OVERHEAD)); // neglect unmanaged\n    __free(oldRoots);\n  }\n  ROOTS = newRoots;\n  CUR = newRoots + oldSize;\n  END = newRoots + newSize;\n}\n\n/** Collects cyclic garbage. */\n// @ts-ignore: decorator\n@global @unsafe @lazy\nexport function __collect(): void {\n  if (isDefined(__GC_ALL_ACYCLIC)) return;\n\n  // markRoots\n  var roots = ROOTS;\n  var cur = roots;\n  for (let pos = cur, end = CUR; pos < end; pos += sizeof<usize>()) {\n    let s = load<Block>(pos);\n    let info = s.gcInfo;\n    if ((info & COLOR_MASK) == COLOR_PURPLE && (info & REFCOUNT_MASK) > 0) {\n      markGray(s);\n      store<Block>(cur, s);\n      cur += sizeof<usize>();\n    } else {\n      if ((info & COLOR_MASK) == COLOR_BLACK && !(info & REFCOUNT_MASK)) {\n        freeBlock(ROOT, s);\n      } else {\n        s.gcInfo = info & ~BUFFERED_MASK;\n      }\n    }\n  }\n  CUR = cur;\n\n  // scanRoots\n  for (let pos = roots; pos < cur; pos += sizeof<usize>()) {\n    scan(load<Block>(pos));\n  }\n\n  // collectRoots\n  for (let pos = roots; pos < cur; pos += sizeof<usize>()) {\n    let s = load<Block>(pos);\n    s.gcInfo = s.gcInfo & ~BUFFERED_MASK;\n    collectWhite(s);\n  }\n  CUR = roots;\n}\n\n/** Marks a block as gray (possible member of cycle) during the collection phase. */\nfunction markGray(s: Block): void {\n  var info = s.gcInfo;\n  if ((info & COLOR_MASK) != COLOR_GRAY) {\n    s.gcInfo = (info & ~COLOR_MASK) | COLOR_GRAY;\n    __visit_members(changetype<usize>(s) + BLOCK_OVERHEAD, VISIT_MARKGRAY);\n  }\n}\n\n/** Scans a block during the collection phase, determining whether it is garbage or not. */\nfunction scan(s: Block): void {\n  var info = s.gcInfo;\n  if ((info & COLOR_MASK) == COLOR_GRAY) {\n    if ((info & REFCOUNT_MASK) > 0) {\n      scanBlack(s);\n    } else {\n      s.gcInfo = (info & ~COLOR_MASK) | COLOR_WHITE;\n      __visit_members(changetype<usize>(s) + BLOCK_OVERHEAD, VISIT_SCAN);\n    }\n  }\n}\n\n/** Marks a block as black (in use) if it was found to be reachable during the collection phase. */\nfunction scanBlack(s: Block): void {\n  s.gcInfo = (s.gcInfo & ~COLOR_MASK) | COLOR_BLACK;\n  __visit_members(changetype<usize>(s) + BLOCK_OVERHEAD, VISIT_SCANBLACK);\n}\n\n/** Collects all white (member of a garbage cycle) nodes when completing the collection phase.  */\nfunction collectWhite(s: Block): void {\n  var info = s.gcInfo;\n  if ((info & COLOR_MASK) == COLOR_WHITE && !(info & BUFFERED_MASK)) {\n    s.gcInfo = (info & ~COLOR_MASK) | COLOR_BLACK;\n    __visit_members(changetype<usize>(s) + BLOCK_OVERHEAD, VISIT_COLLECTWHITE);\n    freeBlock(ROOT, s);\n  }\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __retain(ptr: usize): usize {\n  if (ptr > __heap_base) increment(changetype<Block>(ptr - BLOCK_OVERHEAD));\n  return ptr;\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __release(ptr: usize): void {\n  if (ptr > __heap_base) decrement(changetype<Block>(ptr - BLOCK_OVERHEAD));\n}\n","import { AL_BITS, AL_MASK, DEBUG, BLOCK, BLOCK_OVERHEAD, BLOCK_MAXSIZE } from \"rt/common\";\nimport { onfree, onalloc, onrealloc } from \"./rtrace\";\nimport { REFCOUNT_MASK } from \"./pure\";\n\n/////////////////////// The TLSF (Two-Level Segregate Fit) memory allocator ///////////////////////\n//                             see: http://www.gii.upv.es/tlsf/\n\n// - `ffs(x)` is equivalent to `ctz(x)` with x != 0\n// - `fls(x)` is equivalent to `sizeof(x) * 8 - clz(x) - 1`\n\n// ╒══════════════ Block size interpretation (32-bit) ═════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┼─┴─┴─┴─╫─┴─┴─┴─┤\n// │ |                    FL                       │ SB = SL + AL  │ ◄─ usize\n// └───────────────────────────────────────────────┴───────╨───────┘\n// FL: first level, SL: second level, AL: alignment, SB: small block\n\n// @ts-ignore: decorator\n@inline const SL_BITS: u32 = 4;\n// @ts-ignore: decorator\n@inline const SL_SIZE: u32 = 1 << SL_BITS;\n\n// @ts-ignore: decorator\n@inline const SB_BITS: u32 = SL_BITS + AL_BITS;\n// @ts-ignore: decorator\n@inline const SB_SIZE: u32 = 1 << SB_BITS;\n\n// @ts-ignore: decorator\n@inline const FL_BITS: u32 = 31 - SB_BITS;\n\n// [00]: < 256B (SB)  [12]: < 1M\n// [01]: < 512B       [13]: < 2M\n// [02]: < 1K         [14]: < 4M\n// [03]: < 2K         [15]: < 8M\n// [04]: < 4K         [16]: < 16M\n// [05]: < 8K         [17]: < 32M\n// [06]: < 16K        [18]: < 64M\n// [07]: < 32K        [19]: < 128M\n// [08]: < 64K        [20]: < 256M\n// [09]: < 128K       [21]: < 512M\n// [10]: < 256K       [22]: <= 1G - OVERHEAD\n// [11]: < 512K\n// VMs limit to 2GB total (currently), making one 1G block max (or three 512M etc.) due to block overhead\n\n// Tags stored in otherwise unused alignment bits\n\n// @ts-ignore: decorator\n@inline const FREE: usize = 1 << 0;\n// @ts-ignore: decorator\n@inline const LEFTFREE: usize = 1 << 1;\n// @ts-ignore: decorator\n@inline const TAGS_MASK: usize = FREE | LEFTFREE; // <= AL_MASK\n\n// ╒════════════════════ Block layout (32-bit) ════════════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┼─┼─┼─┤ overhead   ┐\n// │                          size                           │0│L│F│ ◄─┐ info\n// ├─────────────────────────────────────────────────────────┴─┴─┴─┤   │\n// │                                                               │   │\n// │               ... additional runtime overhead ...             │   │\n// │                                                               │   │\n// ╞═══════════════════════════════════════════════════════════════╡   │      ┐ ┘\n// │                        if free: ◄ prev                        │ ◄─┤ usize\n// ├───────────────────────────────────────────────────────────────┤   │\n// │                        if free: next ►                        │ ◄─┤\n// ├───────────────────────────────────────────────────────────────┤   │\n// │                             ...                               │   │    = 0\n// ├───────────────────────────────────────────────────────────────┤   │\n// │                        if free: back ▲                        │ ◄─┘\n// └───────────────────────────────────────────────────────────────┘ payload  ┘ >= MIN SIZE\n// F: FREE, L: LEFTFREE\n@unmanaged export class Block extends BLOCK {\n\n  /** Previous free block, if any. Only valid if free, otherwise part of payload. */\n  prev: Block | null;\n  /** Next free block, if any. Only valid if free, otherwise part of payload. */\n  next: Block | null;\n\n  // If the block is free, there is a 'back'reference at its end pointing at its start.\n}\n\n// Block constants. A block must have a minimum size of three pointers so it can hold `prev`,\n// `next` and `back` if free.\n\n// @ts-ignore: decorator\n@inline const BLOCK_MINSIZE: usize = (3 * sizeof<usize>() + AL_MASK) & ~AL_MASK; // prev + next + back\n// @ts-ignore: decorator\n// @inline const BLOCK_MAXSIZE: usize = 1 << (FL_BITS + SB_BITS - 1); // exclusive, lives in common.ts\n\n/** Gets the left block of a block. Only valid if the left block is free. */\n// @ts-ignore: decorator\n@inline function GETFREELEFT(block: Block): Block {\n  return load<Block>(changetype<usize>(block) - sizeof<usize>());\n}\n\n/** Gets the right block of of a block by advancing to the right by its size. */\n// @ts-ignore: decorator\n@inline function GETRIGHT(block: Block): Block {\n  return changetype<Block>(changetype<usize>(block) + BLOCK_OVERHEAD + (block.mmInfo & ~TAGS_MASK));\n}\n\n// ╒═════════════════════ Root layout (32-bit) ════════════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┤          ┐\n// │        0        |           flMap                            S│ ◄────┐\n// ╞═══════════════════════════════════════════════════════════════╡      │\n// │                           slMap[0] S                          │ ◄─┐  │\n// ├───────────────────────────────────────────────────────────────┤   │  │\n// │                           slMap[1]                            │ ◄─┤  │\n// ├───────────────────────────────────────────────────────────────┤  u32 │\n// │                           slMap[22]                           │ ◄─┘  │\n// ╞═══════════════════════════════════════════════════════════════╡    usize\n// │                            head[0]                            │ ◄────┤\n// ├───────────────────────────────────────────────────────────────┤      │\n// │                              ...                              │ ◄────┤\n// ├───────────────────────────────────────────────────────────────┤      │\n// │                           head[367]                           │ ◄────┤\n// ╞═══════════════════════════════════════════════════════════════╡      │\n// │                             tail                              │ ◄────┘\n// └───────────────────────────────────────────────────────────────┘   SIZE   ┘\n// S: Small blocks map\n@unmanaged class Root {\n  /** First level bitmap. */\n  flMap: usize;\n}\n\n// Root constants. Where stuff is stored inside of the root structure.\n\n// @ts-ignore: decorator\n@inline const SL_START: usize = sizeof<usize>();\n// @ts-ignore: decorator\n@inline const SL_END: usize = SL_START + (FL_BITS << alignof<u32>());\n// @ts-ignore: decorator\n@inline const HL_START: usize = (SL_END + AL_MASK) & ~AL_MASK;\n// @ts-ignore: decorator\n@inline const HL_END: usize = HL_START + FL_BITS * SL_SIZE * sizeof<usize>();\n// @ts-ignore: decorator\n@inline const ROOT_SIZE: usize = HL_END + sizeof<usize>();\n\n// @ts-ignore: decorator\n@lazy export var ROOT: Root;\n\n/** Gets the second level map of the specified first level. */\n// @ts-ignore: decorator\n@inline function GETSL(root: Root, fl: usize): u32 {\n  return load<u32>(\n    changetype<usize>(root) + (fl << alignof<u32>()),\n    SL_START\n  );\n}\n\n/** Sets the second level map of the specified first level. */\n// @ts-ignore: decorator\n@inline function SETSL(root: Root, fl: usize, slMap: u32): void {\n  store<u32>(\n    changetype<usize>(root) + (fl << alignof<u32>()),\n    slMap,\n    SL_START\n  );\n}\n\n/** Gets the head of the free list for the specified combination of first and second level. */\n// @ts-ignore: decorator\n@inline function GETHEAD(root: Root, fl: usize, sl: u32): Block | null {\n  return load<Block>(\n    changetype<usize>(root) + (((fl << SL_BITS) + <usize>sl) << alignof<usize>()),\n    HL_START\n  );\n}\n\n/** Sets the head of the free list for the specified combination of first and second level. */\n// @ts-ignore: decorator\n@inline function SETHEAD(root: Root, fl: usize, sl: u32, head: Block | null): void {\n  store<Block>(\n    changetype<usize>(root) + (((fl << SL_BITS) + <usize>sl) << alignof<usize>()),\n    head,\n    HL_START\n  );\n}\n\n/** Gets the tail block.. */\n// @ts-ignore: decorator\n@inline function GETTAIL(root: Root): Block {\n  return load<Block>(\n    changetype<usize>(root),\n    HL_END\n  );\n}\n\n/** Sets the tail block. */\n// @ts-ignore: decorator\n@inline function SETTAIL(root: Root, tail: Block): void {\n  store<Block>(\n    changetype<usize>(root),\n    tail,\n    HL_END\n  );\n}\n\n/** Inserts a previously used block back into the free list. */\nfunction insertBlock(root: Root, block: Block): void {\n  if (DEBUG) assert(block); // cannot be null\n  var blockInfo = block.mmInfo;\n  if (DEBUG) assert(blockInfo & FREE); // must be free\n\n  var right = GETRIGHT(block);\n  var rightInfo = right.mmInfo;\n\n  // merge with right block if also free\n  if (rightInfo & FREE) {\n    let newSize = (blockInfo & ~TAGS_MASK) + BLOCK_OVERHEAD + (rightInfo & ~TAGS_MASK);\n    if (newSize < BLOCK_MAXSIZE) {\n      removeBlock(root, right);\n      block.mmInfo = blockInfo = (blockInfo & TAGS_MASK) | newSize;\n      right = GETRIGHT(block);\n      rightInfo = right.mmInfo;\n      // 'back' is set below\n    }\n  }\n\n  // merge with left block if also free\n  if (blockInfo & LEFTFREE) {\n    let left = GETFREELEFT(block);\n    let leftInfo = left.mmInfo;\n    if (DEBUG) assert(leftInfo & FREE); // must be free according to right tags\n    let newSize = (leftInfo & ~TAGS_MASK) + BLOCK_OVERHEAD + (blockInfo & ~TAGS_MASK);\n    if (newSize < BLOCK_MAXSIZE) {\n      removeBlock(root, left);\n      left.mmInfo = blockInfo = (leftInfo & TAGS_MASK) | newSize;\n      block = left;\n      // 'back' is set below\n    }\n  }\n\n  right.mmInfo = rightInfo | LEFTFREE;\n  // right is no longer used now, hence rightInfo is not synced\n\n  // we now know the size of the block\n  var size = blockInfo & ~TAGS_MASK;\n  if (DEBUG) assert(size >= BLOCK_MINSIZE && size < BLOCK_MAXSIZE); // must be a valid size\n  if (DEBUG) assert(changetype<usize>(block) + BLOCK_OVERHEAD + size == changetype<usize>(right)); // must match\n\n  // set 'back' to itself at the end of block\n  store<Block>(changetype<usize>(right) - sizeof<usize>(), block);\n\n  // mapping_insert\n  var fl: usize, sl: u32;\n  if (size < SB_SIZE) {\n    fl = 0;\n    sl = <u32>(size >> AL_BITS);\n  } else {\n    const inv: usize = sizeof<usize>() * 8 - 1;\n    fl = inv - clz<usize>(size);\n    sl = <u32>((size >> (fl - SL_BITS)) ^ (1 << SL_BITS));\n    fl -= SB_BITS - 1;\n  }\n  if (DEBUG) assert(fl < FL_BITS && sl < SL_SIZE); // fl/sl out of range\n\n  // perform insertion\n  var head = GETHEAD(root, fl, sl);\n  block.prev = null;\n  block.next = head;\n  if (head) head.prev = block;\n  SETHEAD(root, fl, sl, block);\n\n  // update first and second level maps\n  root.flMap |= (1 << fl);\n  SETSL(root, fl, GETSL(root, fl) | (1 << sl));\n}\n\n/** Removes a free block from internal lists. */\nfunction removeBlock(root: Root, block: Block): void {\n  var blockInfo = block.mmInfo;\n  if (DEBUG) assert(blockInfo & FREE); // must be free\n  var size = blockInfo & ~TAGS_MASK;\n  if (DEBUG) assert(size >= BLOCK_MINSIZE && size < BLOCK_MAXSIZE); // must be valid\n\n  // mapping_insert\n  var fl: usize, sl: u32;\n  if (size < SB_SIZE) {\n    fl = 0;\n    sl = <u32>(size >> AL_BITS);\n  } else {\n    const inv: usize = sizeof<usize>() * 8 - 1;\n    fl = inv - clz<usize>(size);\n    sl = <u32>((size >> (fl - SL_BITS)) ^ (1 << SL_BITS));\n    fl -= SB_BITS - 1;\n  }\n  if (DEBUG) assert(fl < FL_BITS && sl < SL_SIZE); // fl/sl out of range\n\n  // link previous and next free block\n  var prev = block.prev;\n  var next = block.next;\n  if (prev) prev.next = next;\n  if (next) next.prev = prev;\n\n  // update head if we are removing it\n  if (block == GETHEAD(root, fl, sl)) {\n    SETHEAD(root, fl, sl, next);\n\n    // clear second level map if head is empty now\n    if (!next) {\n      let slMap = GETSL(root, fl);\n      SETSL(root, fl, slMap &= ~(1 << sl));\n\n      // clear first level map if second level is empty now\n      if (!slMap) root.flMap &= ~(1 << fl);\n    }\n  }\n  // note: does not alter left/back because it is likely that splitting\n  // is performed afterwards, invalidating those changes. so, the caller\n  // must perform those updates.\n}\n\n/** Searches for a free block of at least the specified size. */\nfunction searchBlock(root: Root, size: usize): Block | null {\n  // size was already asserted by caller\n\n  // mapping_search\n  var fl: usize, sl: u32;\n  if (size < SB_SIZE) {\n    fl = 0;\n    sl = <u32>(size >> AL_BITS);\n  } else {\n    const halfMaxSize = BLOCK_MAXSIZE >> 1; // don't round last fl\n    const inv: usize = sizeof<usize>() * 8 - 1;\n    const invRound = inv - SL_BITS;\n    let requestSize = size < halfMaxSize\n      ? size + (1 << (invRound - clz<usize>(size))) - 1\n      : size;\n    fl = inv - clz<usize>(requestSize);\n    sl = <u32>((requestSize >> (fl - SL_BITS)) ^ (1 << SL_BITS));\n    fl -= SB_BITS - 1;\n  }\n  if (DEBUG) assert(fl < FL_BITS && sl < SL_SIZE); // fl/sl out of range\n\n  // search second level\n  var slMap = GETSL(root, fl) & (~0 << sl);\n  var head: Block | null = null;\n  if (!slMap) {\n    // search next larger first level\n    let flMap = root.flMap & (~0 << (fl + 1));\n    if (!flMap) {\n      head = null;\n    } else {\n      fl = ctz<usize>(flMap);\n      slMap = GETSL(root, fl);\n      if (DEBUG) assert(slMap);  // can't be zero if fl points here\n      head = GETHEAD(root, fl, ctz<u32>(slMap));\n    }\n  } else {\n    head = GETHEAD(root, fl, ctz<u32>(slMap));\n  }\n  return head;\n}\n\n/** Prepares the specified block before (re-)use, possibly splitting it. */\nfunction prepareBlock(root: Root, block: Block, size: usize): void {\n  // size was already asserted by caller\n\n  var blockInfo = block.mmInfo;\n  if (DEBUG) assert(!(size & AL_MASK)); // size must be aligned so the new block is\n\n  // split if the block can hold another MINSIZE block incl. overhead\n  var remaining = (blockInfo & ~TAGS_MASK) - size;\n  if (remaining >= BLOCK_OVERHEAD + BLOCK_MINSIZE) {\n    block.mmInfo = size | (blockInfo & LEFTFREE); // also discards FREE\n\n    let spare = changetype<Block>(changetype<usize>(block) + BLOCK_OVERHEAD + size);\n    spare.mmInfo = (remaining - BLOCK_OVERHEAD) | FREE; // not LEFTFREE\n    insertBlock(root, spare); // also sets 'back'\n\n  // otherwise tag block as no longer FREE and right as no longer LEFTFREE\n  } else {\n    block.mmInfo = blockInfo & ~FREE;\n    GETRIGHT(block).mmInfo &= ~LEFTFREE;\n  }\n}\n\n/** Adds more memory to the pool. */\nfunction addMemory(root: Root, start: usize, end: usize): bool {\n  if (DEBUG) {\n    assert(\n      start <= end &&       // must be valid\n      !(start & AL_MASK) && // must be aligned\n      !(end & AL_MASK)      // must be aligned\n    );\n  }\n\n  var tail = GETTAIL(root);\n  var tailInfo: usize = 0;\n  if (tail) { // more memory\n    if (DEBUG) assert(start >= changetype<usize>(tail) + BLOCK_OVERHEAD);\n\n    // merge with current tail if adjacent\n    if (start - BLOCK_OVERHEAD == changetype<usize>(tail)) {\n      start -= BLOCK_OVERHEAD;\n      tailInfo = tail.mmInfo;\n    } else {\n      // We don't do this, but a user might `memory.grow` manually\n      // leading to non-adjacent pages managed by TLSF.\n    }\n\n  } else if (DEBUG) { // first memory\n    assert(start >= changetype<usize>(root) + ROOT_SIZE); // starts after root\n  }\n\n  // check if size is large enough for a free block and the tail block\n  var size = end - start;\n  if (size < BLOCK_OVERHEAD + BLOCK_MINSIZE + BLOCK_OVERHEAD) {\n    return false;\n  }\n\n  // left size is total minus its own and the zero-length tail's header\n  var leftSize = size - (BLOCK_OVERHEAD << 1);\n  var left = changetype<Block>(start);\n  left.mmInfo = leftSize | FREE | (tailInfo & LEFTFREE);\n  left.prev = null;\n  left.next = null;\n\n  // tail is a zero-length used block\n  tail = changetype<Block>(start + size - BLOCK_OVERHEAD);\n  tail.mmInfo = 0 | LEFTFREE;\n  SETTAIL(root, tail);\n\n  insertBlock(root, left); // also merges with free left before tail / sets 'back'\n\n  return true;\n}\n\n/** Grows memory to fit at least another block of the specified size. */\nfunction growMemory(root: Root, size: usize): void {\n  if (ASC_LOW_MEMORY_LIMIT) {\n    unreachable();\n    return;\n  }\n  // Here, both rounding performed in searchBlock ...\n  const halfMaxSize = BLOCK_MAXSIZE >> 1;\n  if (size < halfMaxSize) { // don't round last fl\n    const invRound = (sizeof<usize>() * 8 - 1) - SL_BITS;\n    size += (1 << (invRound - clz<usize>(size))) - 1;\n  }\n  // and additional BLOCK_OVERHEAD must be taken into account. If we are going\n  // to merge with the tail block, that's one time, otherwise it's two times.\n  var pagesBefore = memory.size();\n  size += BLOCK_OVERHEAD << usize((<usize>pagesBefore << 16) - BLOCK_OVERHEAD != changetype<usize>(GETTAIL(root)));\n  var pagesNeeded = <i32>(((size + 0xffff) & ~0xffff) >>> 16);\n  var pagesWanted = max(pagesBefore, pagesNeeded); // double memory\n  if (memory.grow(pagesWanted) < 0) {\n    if (memory.grow(pagesNeeded) < 0) unreachable();\n  }\n  var pagesAfter = memory.size();\n  addMemory(root, <usize>pagesBefore << 16, <usize>pagesAfter << 16);\n}\n\n/** Prepares and checks an allocation size. */\nfunction prepareSize(size: usize): usize {\n  if (size >= BLOCK_MAXSIZE) throw new Error(\"allocation too large\");\n  return max<usize>((size + AL_MASK) & ~AL_MASK, BLOCK_MINSIZE); // align and ensure min size\n}\n\n/** Initilizes the root structure. */\nexport function maybeInitialize(): Root {\n  var root = ROOT;\n  if (!root) {\n    let rootOffset = (__heap_base + AL_MASK) & ~AL_MASK;\n    let pagesBefore = memory.size();\n    let pagesNeeded = <i32>((((rootOffset + ROOT_SIZE) + 0xffff) & ~0xffff) >>> 16);\n    if (pagesNeeded > pagesBefore && memory.grow(pagesNeeded - pagesBefore) < 0) unreachable();\n    root = changetype<Root>(rootOffset);\n    root.flMap = 0;\n    SETTAIL(root, changetype<Block>(0));\n    for (let fl: usize = 0; fl < FL_BITS; ++fl) {\n      SETSL(root, fl, 0);\n      for (let sl: u32 = 0; sl < SL_SIZE; ++sl) {\n        SETHEAD(root, fl, sl, null);\n      }\n    }\n    let memStart = (rootOffset + ROOT_SIZE + AL_MASK) & ~AL_MASK;\n    if (ASC_LOW_MEMORY_LIMIT) {\n      const memEnd = <usize>ASC_LOW_MEMORY_LIMIT & ~AL_MASK;\n      if (memStart <= memEnd) addMemory(root, memStart, memEnd);\n      else unreachable(); // low memory limit already exceeded\n    } else {\n      addMemory(root, memStart, memory.size() << 16);\n    }\n    ROOT = root;\n  }\n  return root;\n}\n\n// @ts-ignore: decorator\n@lazy\nvar collectLock: bool = false;\n\n/** Allocates a block of the specified size. */\nexport function allocateBlock(root: Root, size: usize, id: u32): Block {\n  if (DEBUG) assert(!collectLock); // must not allocate while collecting\n  var payloadSize = prepareSize(size);\n  var block = searchBlock(root, payloadSize);\n  if (!block) {\n    if (gc.auto) {\n      if (DEBUG) collectLock = true;\n      __collect();\n      if (DEBUG) collectLock = false;\n      block = searchBlock(root, payloadSize);\n      if (!block) {\n        growMemory(root, payloadSize);\n        block = changetype<Block>(searchBlock(root, payloadSize));\n        if (DEBUG) assert(block); // must be found now\n      }\n    } else {\n      growMemory(root, payloadSize);\n      block = changetype<Block>(searchBlock(root, payloadSize));\n      if (DEBUG) assert(block); // must be found now\n    }\n  }\n  if (DEBUG) assert((block.mmInfo & ~TAGS_MASK) >= payloadSize); // must fit\n  block.gcInfo = 0; // RC=0\n  block.rtId = id;\n  block.rtSize = <u32>size;\n  removeBlock(root, <Block>block);\n  prepareBlock(root, <Block>block, payloadSize);\n  if (isDefined(ASC_RTRACE)) onalloc(<Block>block);\n  return <Block>block;\n}\n\n/** Reallocates a block to the specified size. */\nexport function reallocateBlock(root: Root, block: Block, size: usize): Block {\n  var payloadSize = prepareSize(size);\n  var blockInfo = block.mmInfo;\n\n  // possibly split and update runtime size if it still fits\n  if (payloadSize <= (blockInfo & ~TAGS_MASK)) {\n    prepareBlock(root, block, payloadSize);\n    block.rtSize = <u32>size;\n    return block;\n  }\n\n  // merge with right free block if merger is large enough\n  var right = GETRIGHT(block);\n  var rightInfo = right.mmInfo;\n  if (rightInfo & FREE) {\n    let mergeSize = (blockInfo & ~TAGS_MASK) + BLOCK_OVERHEAD + (rightInfo & ~TAGS_MASK);\n    if (mergeSize >= payloadSize) {\n      removeBlock(root, right);\n      // TODO: this can yield an intermediate block larger than BLOCK_MAXSIZE, which\n      // is immediately split though. does this trigger any assertions / issues?\n      block.mmInfo = (blockInfo & TAGS_MASK) | mergeSize;\n      block.rtSize = <u32>size;\n      prepareBlock(root, block, payloadSize);\n      return block;\n    }\n  }\n\n  // otherwise move the block\n  var newBlock = allocateBlock(root, size, block.rtId); // may invalidate cached blockInfo\n  newBlock.gcInfo = block.gcInfo; // keep RC\n  memory.copy(changetype<usize>(newBlock) + BLOCK_OVERHEAD, changetype<usize>(block) + BLOCK_OVERHEAD, size);\n  if (changetype<usize>(block) >= __heap_base) {\n    if (isDefined(ASC_RTRACE)) onrealloc(block, newBlock);\n    freeBlock(root, block);\n  }\n  return newBlock;\n}\n\n/** Frees a block. */\nexport function freeBlock(root: Root, block: Block): void {\n  var blockInfo = block.mmInfo;\n  block.mmInfo = blockInfo | FREE;\n  insertBlock(root, block);\n  if (isDefined(ASC_RTRACE)) onfree(block);\n}\n\n/** Checks that a used block is valid to be freed or reallocated. */\nfunction checkUsedBlock(ref: usize): Block {\n  var block = changetype<Block>(ref - BLOCK_OVERHEAD);\n  assert(\n    ref != 0 && !(ref & AL_MASK) &&  // must exist and be aligned\n    !(block.mmInfo & FREE) &&        // must be used\n    !(block.gcInfo & ~REFCOUNT_MASK) // not buffered or != BLACK\n  );\n  return block;\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __alloc(size: usize, id: u32): usize {\n  return changetype<usize>(\n    allocateBlock(maybeInitialize(), size, id)\n  ) + BLOCK_OVERHEAD;\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __realloc(ref: usize, size: usize): usize {\n  return changetype<usize>(\n    reallocateBlock(maybeInitialize(), checkUsedBlock(ref), size)\n  ) + BLOCK_OVERHEAD;\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __free(ref: usize): void {\n  freeBlock(maybeInitialize(), checkUsedBlock(ref));\n}\n","/// <reference path=\"./rt/index.d.ts\" />\n\n/** Garbage collector interface. */\nexport namespace gc {\n\n  /** Can be set to `false` to disable automatic collection. Defaults to `true`. */\n  export var auto: bool = true;\n\n  /** Performs a full garbage collection cycle. */\n  export function collect(): void {\n    __collect();\n  }\n}\n","import { log } from './util/log';\r\nimport { exit } from './util/exit';\r\n\r\nconst HEADER = [137,  80,  78,  71,  13,  10,  26,  10] as StaticArray<u8>;\r\nconst HEADER_BITS = 8;\r\n\r\nexport function validateHeader<T>(buffer: T, position: u32): u32 {\r\n  for (let i = 0; i < HEADER_BITS; i++) {\r\n    // @ts-ignore: safe definition checked\r\n    let value = isDefined(unchecked(buffer[0]))\r\n      // @ts-ignore: unchecked is defined\r\n      ? unchecked(buffer[i])\r\n      // @ts-ignore: use regular array access\r\n      : buffer[i];\r\n    if (value!= unchecked(HEADER[i])) {\r\n      log('Invalid header bit at ' + i.toString() + 'th bit. Aborting...');\r\n\r\n      exit(-1);\r\n      return -1;\r\n    }\r\n  }\r\n\r\n  return 7;\r\n}","import { log } from './util/log';\r\n\r\n/*\r\n  Width:              4 bytes\r\n  Height:             4 bytes\r\n  Bit depth:          1 byte\r\n  Color type:         1 byte\r\n  Compression method: 1 byte\r\n  Filter method:      1 byte\r\n  Interlace method:   1 byte\r\n*/\r\nexport class IHDR {\r\n  private static COMPRESSION_METHOD: u8 = 0;\r\n  private static FILTER_METHOD: u8 = 0;\r\n  public bitDepths: StaticArray<u8> = [];\r\n\r\n  constructor(\r\n    public width: u32,\r\n    public height: u32,\r\n    public bitDepth: u8,\r\n    public colorType: u8,\r\n    public compressionMethod: u8,\r\n    public filterMethod: u8,\r\n    public interlaceMethod: u8,\r\n  ) {\r\n    const bitDepths = IHDR.GET_COLOR_TYPES_TO_BITS_DEPTH(colorType);\r\n    if (bitDepths != null) {\r\n      this.bitDepths = bitDepths;\r\n    } else {\r\n      log(colorType.toString() + ' is not a supported color type');\r\n    }\r\n\r\n    if (IHDR.COMPRESSION_METHOD != compressionMethod) {\r\n      log(compressionMethod.toString() + ' is not a supported color type');\r\n    }\r\n\r\n    if (IHDR.FILTER_METHOD != filterMethod) {\r\n      log(filterMethod.toString() + ' is not a supported color type');\r\n    }\r\n  }\r\n}\r\n\r\nexport namespace IHDR {\r\n  export const TYPE = <u32>0x52444849; // : string = 'IHDR';\r\n  export const BYTE_LENGTH = <u8>13;\r\n\r\n  // @ts-ignore\r\n  @inline\r\n  export function GET_COLOR_TYPES_TO_BITS_DEPTH(input: u8): StaticArray<u8> {\r\n    switch (input) {\r\n      case 0: return [1, 2, 4, 8, 16];\r\n      case 3: return [1, 2, 4, 8];\r\n      case 2:\r\n      case 4:\r\n      case 6: return [8, 16];\r\n      default: assert(false);\r\n    }\r\n  }\r\n}\r\n\r\nexport namespace IDAT {\r\n  export const TYPE = <u32>0x54414449; // : string = 'IDAT';\r\n  export const BYTE_LENGTH = <u8>13;\r\n}\r\n\r\nexport namespace IEND {\r\n  export const TYPE = <u32>0x444E4549; // : string = 'IEND';\r\n}\r\n\r\n/*\r\n  This chunk must appear for color type 3, and can appear for color types 2 and 6; it must not appear for color types 0 and 4. If this chunk does appear, it must precede the first IDAT chunk. There must not be more than one PLTE chunk.\r\n\r\n  For color type 3 (indexed color), the PLTE chunk is required. The first entry in PLTE is referenced by pixel value 0, the second by pixel value 1, etc. The number of palette entries must not exceed the range that can be represented in the image bit depth (for example, 24 = 16 for a bit depth of 4). It is permissible to have fewer entries than the bit depth would allow. In that case, any out-of-range pixel value found in the image data is an error.\r\n\r\n  For color types 2 and 6 (truecolor and truecolor with alpha), the PLTE chunk is optional. If present, it provides a suggested set of from 1 to 256 colors to which the truecolor image can be quantized if the viewer cannot display truecolor directly. If neither PLTE nor sPLT is present, such a viewer will need to select colors on its own, but it is often preferable for this to be done once by the encoder. (See Recommendations for Encoders: Suggested palettes.) \r\n*/\r\nexport class PLTE {\r\n  constructor(\r\n    public R: u8,\r\n    public G: u8,\r\n    public B: u8,\r\n    public colorType: u8 = 3,\r\n  ) {\r\n    if (colorType == 0 || colorType == 4) {\r\n      log(colorType.toString() + ' is not a supported color type for PETE');\r\n    }\r\n  };\r\n}\r\n\r\nexport namespace PLTE {\r\n  export const TYPE = <u8>0x45544C50;\r\n  export const BYTE_LENGTH = <u8>3;\r\n}\r\n\r\nexport class sRGB {\r\n  constructor(\r\n    public renderingIntent: u8,\r\n  ) {\r\n    // valid values are 0, 1, 2, and 3\r\n    if (renderingIntent & 0xFC) {\r\n      log(renderingIntent.toString() + ' is not a valid rendering intent for sRGB');\r\n    }\r\n  }\r\n}\r\n\r\nexport namespace sRGB {\r\n  export const TYPE = <u32>0x42475273;\r\n  export const BYTE_LENGTH = <u8>1;\r\n}\r\n\r\nexport class gAMA {\r\n  constructor(\r\n    public gamma: u32,\r\n  ) {}\r\n\r\n  getGamma(): u32 {\r\n    return this.gamma * 100000;\r\n  }\r\n}\r\n\r\nexport namespace gAMA {\r\n  export const TYPE = <u32>0x414d4167;\r\n  export const BYTE_LENGTH = <u8>4;\r\n}\r\n","export const UInt8ArrayID: i32 = idof<Uint8Array>();","/// <reference path=\"./rt/index.d.ts\" />\n\nimport { BLOCK, BLOCK_MAXSIZE, BLOCK_OVERHEAD } from \"./rt/common\";\nimport { idof } from \"./builtins\";\nimport { Array } from \"./array\";\nimport { E_INDEXOUTOFRANGE, E_INVALIDLENGTH, E_HOLEYARRAY } from \"./util/error\";\nimport { joinBooleanArray, joinIntegerArray, joinFloatArray, joinStringArray, joinReferenceArray } from \"./util/string\";\n\n@sealed\nexport class StaticArray<T> {\n  [key: number]: T;\n\n  // Note that the interface of StaticArray instances must be a semantically\n  // compatible subset of Array<T> in order for syntax highlighting to work\n  // properly, for instance when creating static arrays from array literals.\n  // The additionally provided static methods take care of dealing with static\n  // arrays exclusively, without having to convert to Array<T> first.\n\n  static fromArray<T>(source: Array<T>): StaticArray<T> {\n    var length = source.length;\n    var outSize = <usize>length << alignof<T>();\n    var out = __alloc(outSize, idof<StaticArray<T>>());\n    if (isManaged<T>()) {\n      let sourcePtr = source.dataStart;\n      for (let i = 0; i < length; ++i) {\n        let off = <usize>i << alignof<T>();\n        store<usize>(out + off, __retain(load<usize>(sourcePtr + off)));\n      }\n    } else {\n      memory.copy(out, source.dataStart, outSize);\n    }\n    return changetype<StaticArray<T>>(out);\n  }\n\n  static concat<T>(source: StaticArray<T>, other: StaticArray<T>): StaticArray<T> {\n    var sourceLen = source.length;\n    var otherLen = select(0, other.length, other === null);\n    var outLen = sourceLen + otherLen;\n    if (<u32>outLen > <u32>BLOCK_MAXSIZE >>> alignof<T>()) throw new Error(E_INVALIDLENGTH);\n    var out = changetype<StaticArray<T>>(__alloc(<usize>outLen << alignof<T>(), idof<StaticArray<T>>())); // retains\n    var outStart = changetype<usize>(out);\n    var sourceSize = <usize>sourceLen << alignof<T>();\n    if (isManaged<T>()) {\n      for (let offset: usize = 0; offset < sourceSize; offset += sizeof<T>()) {\n        let ref = load<usize>(changetype<usize>(source) + offset);\n        store<usize>(outStart + offset, __retain(ref));\n      }\n      outStart += sourceSize;\n      let otherSize = <usize>otherLen << alignof<T>();\n      for (let offset: usize = 0; offset < otherSize; offset += sizeof<T>()) {\n        let ref = load<usize>(changetype<usize>(other) + offset);\n        store<usize>(outStart + offset, __retain(ref));\n      }\n    } else {\n      memory.copy(outStart, changetype<usize>(source), sourceSize);\n      memory.copy(outStart + sourceSize, changetype<usize>(other), <usize>otherLen << alignof<T>());\n    }\n    return out;\n  }\n\n  static slice<T>(source: StaticArray<T>, start: i32 = 0, end: i32 = i32.MAX_VALUE): StaticArray<T> {\n    var length = source.length;\n    start = start < 0 ? max(start + length, 0) : min(start, length);\n    end   = end   < 0 ? max(end   + length, 0) : min(end  , length);\n    length = max(end - start, 0);\n    var sliceSize = <usize>length << alignof<T>();\n    var slice = changetype<StaticArray<T>>(__alloc(sliceSize, idof<StaticArray<T>>())); // retains\n    var sourcePtr = changetype<usize>(source) + (<usize>start << alignof<T>());\n    if (isManaged<T>()) {\n      let off: usize = 0;\n      while (off < sliceSize) {\n        let ref = load<usize>(sourcePtr + off);\n        store<usize>(changetype<usize>(slice) + off, __retain(ref));\n        off += sizeof<usize>();\n      }\n    } else {\n      memory.copy(changetype<usize>(slice), sourcePtr, sliceSize);\n    }\n    return slice;\n  }\n\n  constructor(length: i32) {\n    if (<u32>length > <u32>BLOCK_MAXSIZE >>> alignof<T>()) throw new RangeError(E_INVALIDLENGTH);\n    var outSize = <usize>length << alignof<T>();\n    var out = __alloc(outSize, idof<StaticArray<T>>());\n    memory.fill(out, 0, outSize);\n    return changetype<StaticArray<T>>(out); // retains\n  }\n\n  get length(): i32 {\n    return changetype<BLOCK>(changetype<usize>(this) - BLOCK_OVERHEAD).rtSize >>> alignof<T>();\n  }\n\n  @operator(\"[]\") private __get(index: i32): T {\n    if (<u32>index >= <u32>this.length) throw new RangeError(E_INDEXOUTOFRANGE);\n    var value = this.__unchecked_get(index);\n    if (isReference<T>()) {\n      if (!isNullable<T>()) {\n        if (!changetype<usize>(value)) throw new Error(E_HOLEYARRAY);\n      }\n    }\n    return value;\n  }\n\n  @unsafe @operator(\"{}\") private __unchecked_get(index: i32): T {\n    return load<T>(changetype<usize>(this) + (<usize>index << alignof<T>()));\n  }\n\n  @operator(\"[]=\") private __set(index: i32, value: T): void {\n    if (<u32>index >= <u32>this.length) throw new RangeError(E_INDEXOUTOFRANGE);\n    this.__unchecked_set(index, value);\n  }\n\n  @unsafe @operator(\"{}=\") private __unchecked_set(index: i32, value: T): void {\n    if (isManaged<T>()) {\n      let offset = changetype<usize>(this) + (<usize>index << alignof<T>());\n      let oldRef = load<usize>(offset);\n      if (changetype<usize>(value) != oldRef) {\n        store<usize>(offset, __retain(changetype<usize>(value)));\n        __release(changetype<usize>(oldRef));\n      }\n    } else {\n      store<T>(changetype<usize>(this) + (<usize>index << alignof<T>()), value);\n    }\n  }\n\n  includes(value: T, fromIndex: i32 = 0): bool {\n    if (isFloat<T>()) {\n      let length = this.length;\n      if (length == 0 || fromIndex >= length) return false;\n      if (fromIndex < 0) fromIndex = max(length + fromIndex, 0);\n      while (fromIndex < length) {\n        let elem = load<T>(changetype<usize>(this) + (<usize>fromIndex << alignof<T>()));\n        // @ts-ignore\n        if (elem == value || isNaN(elem) & isNaN(value)) return true;\n        ++fromIndex;\n      }\n      return false;\n    } else {\n      return this.indexOf(value, fromIndex) >= 0;\n    }\n  }\n\n  indexOf(value: T, fromIndex: i32 = 0): i32 {\n    var length = this.length;\n    if (length == 0 || fromIndex >= length) return -1;\n    if (fromIndex < 0) fromIndex = max(length + fromIndex, 0);\n    while (fromIndex < length) {\n      if (load<T>(changetype<usize>(this) + (<usize>fromIndex << alignof<T>())) == value) return fromIndex;\n      ++fromIndex;\n    }\n    return -1;\n  }\n\n  lastIndexOf(value: T, fromIndex: i32 = this.length): i32 {\n    var length = this.length;\n    if (length == 0) return -1;\n    if (fromIndex < 0) fromIndex = length + fromIndex;\n    else if (fromIndex >= length) fromIndex = length - 1;\n    while (fromIndex >= 0) {\n      if (load<T>(changetype<usize>(this) + (<usize>fromIndex << alignof<T>())) == value) return fromIndex;\n      --fromIndex;\n    }\n    return -1;\n  }\n\n  concat(other: Array<T>): Array<T> {\n    var thisLen = this.length;\n    var otherLen = select(0, other.length, other === null);\n    var outLen = thisLen + otherLen;\n    if (<u32>outLen > <u32>BLOCK_MAXSIZE >>> alignof<T>()) throw new Error(E_INVALIDLENGTH);\n    var out = changetype<Array<T>>(__allocArray(outLen, alignof<T>(), idof<Array<T>>())); // retains\n    var outStart = out.dataStart;\n    var thisSize = <usize>thisLen << alignof<T>();\n    if (isManaged<T>()) {\n      let thisStart = changetype<usize>(this);\n      for (let offset: usize = 0; offset < thisSize; offset += sizeof<T>()) {\n        let ref = load<usize>(thisStart + offset);\n        store<usize>(outStart + offset, __retain(ref));\n      }\n      outStart += thisSize;\n      let otherStart = other.dataStart;\n      let otherSize = <usize>otherLen << alignof<T>();\n      for (let offset: usize = 0; offset < otherSize; offset += sizeof<T>()) {\n        let ref = load<usize>(otherStart + offset);\n        store<usize>(outStart + offset, __retain(ref));\n      }\n    } else {\n      memory.copy(outStart, changetype<usize>(this), thisSize);\n      memory.copy(outStart + thisSize, other.dataStart, <usize>otherLen << alignof<T>());\n    }\n    return out;\n  }\n\n  slice(start: i32 = 0, end: i32 = i32.MAX_VALUE): Array<T> {\n    var length = this.length;\n    start = start < 0 ? max(start + length, 0) : min(start, length);\n    end   = end   < 0 ? max(end   + length, 0) : min(end  , length);\n    length = max(end - start, 0);\n    var slice = changetype<Array<T>>(__allocArray(length, alignof<T>(), idof<Array<T>>())); // retains\n    var sliceBase = slice.dataStart;\n    var thisBase = changetype<usize>(this) + (<usize>start << alignof<T>());\n    if (isManaged<T>()) {\n      let off = <usize>0;\n      let end = <usize>length << alignof<usize>();\n      while (off < end) {\n        let ref = load<usize>(thisBase + off);\n        store<usize>(sliceBase + off, __retain(ref));\n        off += sizeof<usize>();\n      }\n    } else {\n      memory.copy(sliceBase, thisBase, length << alignof<T>());\n    }\n    return slice;\n  }\n\n  join(separator: string = \",\"): string {\n    if (isBoolean<T>())   return joinBooleanArray(changetype<usize>(this), this.length, separator);\n    if (isInteger<T>())   return joinIntegerArray<T>(changetype<usize>(this), this.length, separator);\n    if (isFloat<T>())     return joinFloatArray<T>(changetype<usize>(this), this.length, separator);\n    if (ASC_SHRINK_LEVEL < 1) {\n      if (isString<T>())  return joinStringArray(changetype<usize>(this), this.length, separator);\n    }\n    if (isReference<T>()) return joinReferenceArray<T>(changetype<usize>(this), this.length, separator);\n    ERROR(\"unspported element type\");\n    return <string>unreachable();\n  }\n\n  toString(): string {\n    return this.join();\n  }\n\n  // RT integration\n\n  @unsafe private __visit_impl(cookie: u32): void {\n    if (isManaged<T>()) {\n      let cur = changetype<usize>(this);\n      let end = cur + changetype<BLOCK>(changetype<usize>(this) - BLOCK_OVERHEAD).rtSize;\n      while (cur < end) {\n        let val = load<usize>(cur);\n        if (val) __visit(val, cookie);\n        cur += sizeof<usize>();\n      }\n    }\n  }\n}\n"]}